{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3mkclbJyDLf"
      },
      "source": [
        "**1. Title & Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbTjzA3Dx0qI"
      },
      "outputs": [],
      "source": [
        "# ðŸ“Œ AdaFLUX-LoRA Similarity & Divergence Analysis Notebook\n",
        "# --------------------------------------------------------\n",
        "# This notebook evaluates how similar different client models are using:\n",
        "# âœ“ Jensenâ€“Shannon Divergence\n",
        "# âœ“ Cosine similarity of model logits\n",
        "# âœ“ Cluster vs Non-cluster model performance\n",
        "\n",
        "import os, sys, json\n",
        "import numpy as np\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from itertools import combinations\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import project modules (adjust path if needed)\n",
        "PROJECT_ROOT = Path(\"..\").resolve()\n",
        "sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "from server.router import FLUXRouter\n",
        "from client_adaflux_lora import collect_descriptor_vector, FlowerClient\n",
        "from visualize_clusters import plot_flux_embeddings\n",
        "\n",
        "# HuggingFace utilities\n",
        "from torch.nn.functional import softmax, log_softmax\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ0FWzyHx_xw"
      },
      "source": [
        "**2. Load Saved FL State (Cluster + Params + Assignments)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucy0yD8mx50B"
      },
      "outputs": [],
      "source": [
        "# âœ” Loads server-side cluster assignments and checkpoint paths\n",
        "\n",
        "CHECKPOINT_DIR = Path(\"../checkpoints\")\n",
        "CLUSTER_META_PATH = Path(\"../results/cluster_assignments.json\")\n",
        "\n",
        "if not CLUSTER_META_PATH.exists():\n",
        "    raise FileNotFoundError(\"Cluster metadata not found. Run federated training first.\")\n",
        "\n",
        "with open(CLUSTER_META_PATH, \"r\") as f:\n",
        "    cluster_info = json.load(f)\n",
        "\n",
        "cluster_assignments = cluster_info[\"client_to_cluster\"]\n",
        "clusters = {}\n",
        "for cid, cl in cluster_assignments.items():\n",
        "    clusters.setdefault(str(cl), []).append(str(cid))\n",
        "\n",
        "print(\"ðŸ“Œ Loaded Clusters:\", clusters)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrcMWq_dyK_I"
      },
      "source": [
        "**3. Restore Trained Models (Cluster & Global Baselines)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_JRm-Kvx718"
      },
      "outputs": [],
      "source": [
        "# Load a fresh model for evaluation\n",
        "from models.model_loader import load_base_model  # You already have this in client init\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "client_models = {}\n",
        "global_model = None\n",
        "\n",
        "for cid, ckpt in cluster_info[\"client_checkpoints\"].items():\n",
        "    model = load_base_model()\n",
        "    state = torch.load(ckpt, map_location=device)\n",
        "    tensors = [torch.tensor(t).to(device) for t in state[\"tensors\"]]\n",
        "    keys = state[\"keys\"]\n",
        "\n",
        "    # Inject LoRA params\n",
        "    sd = model.state_dict()\n",
        "    for k, v in zip(keys, tensors): sd[k].copy_(v)\n",
        "\n",
        "    client_models[str(cid)] = model.to(device).eval()\n",
        "\n",
        "# Load global baseline model\n",
        "GLOBAL_CKPT = cluster_info[\"global_checkpoint\"]\n",
        "global_model = load_base_model().to(device)\n",
        "state_global = torch.load(GLOBAL_CKPT, map_location=device)\n",
        "for k, v in zip(state_global[\"keys\"], state_global[\"tensors\"]):\n",
        "    global_model.state_dict()[k].copy_(torch.tensor(v).to(device))\n",
        "\n",
        "print(f\"Loaded: {len(client_models)} client models + global baseline.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84wEv57OyNtT"
      },
      "source": [
        "**4. JS Divergence Function (Cleaned & Efficient)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA2R48N7yQzp"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def js_divergence_matrix(models: dict, dataloader, topk=50):\n",
        "    ids = list(models.keys())\n",
        "    C = len(ids)\n",
        "    matrix = np.zeros((C, C))\n",
        "\n",
        "    for (i, ci), (j, cj) in combinations(list(enumerate(ids)), 2):\n",
        "        Pi_probs, Pj_probs = [], []\n",
        "\n",
        "        for batch in dataloader:\n",
        "            inputs = {k: v.to(device) for k, v in batch[0].items()}\n",
        "            Pi = softmax(models[ci](**inputs).logits, dim=-1)\n",
        "            Pj = softmax(models[cj](**inputs).logits, dim=-1)\n",
        "\n",
        "            # Top-k reduce for speed\n",
        "            idx = torch.topk((Pi + Pj) / 2, topk, dim=-1).indices\n",
        "            Pi = torch.gather(Pi, -1, idx)\n",
        "            Pj = torch.gather(Pj, -1, idx)\n",
        "\n",
        "            M = 0.5 * (Pi + Pj)\n",
        "            js_token = 0.5 * (\n",
        "                torch.sum(Pi * (torch.log(Pi + 1e-9) - torch.log(M + 1e-9)), dim=-1) +\n",
        "                torch.sum(Pj * (torch.log(Pj + 1e-9) - torch.log(M + 1e-9)), dim=-1)\n",
        "            ).mean()\n",
        "\n",
        "            Pi_probs.append(float(js_token))\n",
        "\n",
        "        matrix[i, j] = matrix[j, i] = np.mean(Pi_probs)\n",
        "\n",
        "    return ids, matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ndP5CjEyU27"
      },
      "source": [
        "**5. Run Experiments (Clustered vs Non-clustered)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x5pg1rCyXgs"
      },
      "outputs": [],
      "source": [
        "# Load probe dataset from a real client's eval set\n",
        "example_client = list(client_models.keys())[0]\n",
        "probe_loader = FlowerClient.load_eval_loader(cid=int(example_client))\n",
        "\n",
        "# 1) JS divergence across all clients\n",
        "ids, full_js = js_divergence_matrix(client_models, probe_loader)\n",
        "\n",
        "# 2) JS divergence against global baseline\n",
        "global_compare = []\n",
        "for cid in ids:\n",
        "    _, mat = js_divergence_matrix(\n",
        "        {cid: client_models[cid], \"global\": global_model},\n",
        "        probe_loader\n",
        "    )\n",
        "    global_compare.append(mat[0,1])\n",
        "\n",
        "print(\"JS Divergence vs Global:\\n\", dict(zip(ids, global_compare)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCzOzyAxybF7"
      },
      "source": [
        "**6. Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbNS1XNwyeaP"
      },
      "outputs": [],
      "source": [
        "sns.set(font_scale=1.1)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(full_js, annot=True, fmt=\".03f\", xticklabels=ids, yticklabels=ids, cmap=\"viridis\")\n",
        "plt.title(\"Jensenâ€“Shannon Divergence Between Client Models\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.barplot(x=ids, y=global_compare)\n",
        "plt.ylabel(\"JS Divergence to Global Model\")\n",
        "plt.title(\"Similarity of Each Client to Global Model\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
