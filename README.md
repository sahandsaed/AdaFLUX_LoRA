# AdaFLUX-LoRA: Federated Adaptive LoRA with FLUX-style Clustering

AdaFLUX-LoRA is a federated fine-tuning framework that combines:

- **FLUX-style client descriptors** (data + gradient statistics)
- **Dynamic clustering** of clients based on descriptors
- **Cluster-wise LoRA aggregation** (CFL-style federation)
- **AdaLoRA-style rank adaptation** (handled inside LoRA modules)
- **Routing for unseen clients** based on learned clusters

The codebase is built on top of **Flower**, **PEFT**, and **Transformers**, and currently supports:
- Vision (ViT) and summarization (T5) tasks
- Both **online FL** (server + clients) and **sequential local simulation**

---

## ğŸ“ Repository Structure

```text
.
â”œâ”€â”€ client_adaflux_lora.py       # Flower client (AdaFLUX-LoRA)
â”œâ”€â”€ server_adaflux_lora.py       # Flower server (AdaFLUX-LoRA)
â”œâ”€â”€ fedseq_adaflux_lora.py       # Sequential local FL simulation (no networking)
â”œâ”€â”€ logging_utils.py             # TensorBoard logger helper
â”œâ”€â”€ router.py                    # FLUXRouter for test-time routing
â”œâ”€â”€ visualize_clusters.py        # Cluster embedding visualization (e.g., PCA/UMAP)
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ config.py                # Global config (dataset, model, FL hyperparameters)
â”‚   â”œâ”€â”€ utils.py                 # Plotting, seeding, GPU utils, folder creation
â”‚   â”œâ”€â”€ models.py                # CombinedDataset, ViT/T5 helpers if needed
â”œâ”€â”€ data/
â”‚   â””â”€â”€ cur_datasets/            # Pre-partitioned data per client (vision or summarization)
â”œâ”€â”€ checkpoints/                 # Server-side LoRA checkpoints (online FL)
â”œâ”€â”€ checkpoints_local/           # Local-simulation LoRA checkpoints
â”œâ”€â”€ results/                     # Evaluation metrics (online FL)
â”œâ”€â”€ results_local/               # Metrics from sequential simulation
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
